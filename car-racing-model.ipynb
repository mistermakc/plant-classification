{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Resolution**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part 0: Imports**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **â€¢ Libraries and Module Imports:**\n",
    "\n",
    "Importing the necessary libraries and modules to manipulate and interact with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part I: Setting UP the Environment**\n",
    "\n",
    "Define the environment that will be used - \"CarRaving-v2\" and create an instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the type of environment.\n",
    "environment_name = 'CarRacing-v2'\n",
    "\n",
    "# Creating an instance of it and setting the render mode as \"human\" so the environment can be seen on video.\n",
    "env = gym.make(environment_name, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.  0.], 1.0, (3,), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Action Space.\n",
    "env.action_space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** The used action space will be continuos and have 3 different actions:\n",
    " - **Steering -** [-1 Full Left, + 1 Full Right]\n",
    " - **Gas -** [0,1 Full Gas]\n",
    " - **Brake -** [0,1 Full Brake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (96, 96, 3), uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** The Observation Space will consist of 96x96 RGB (3-channel) pixel frames from the gameplay."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part II: Running a Baseline of Random Episodes**\n",
    "\n",
    "Let the agent take random actions in the environment in order to give a baseline of what to expect from an untrained agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample()\n\u001b[0;32m     24\u001b[0m \u001b[39m# Taking the chosen action in the environment, and get the next state, reward, done flag, and additional info.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m n_state, reward, done, _, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     27\u001b[0m \u001b[39m# Adding the reward for this step to the score.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n",
      "File \u001b[1;32mc:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\envs\\box2d\\car_racing.py:541\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworld\u001b[39m.\u001b[39mStep(\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m FPS, \u001b[39m6\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m, \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m)\n\u001b[0;32m    539\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m FPS\n\u001b[1;32m--> 541\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render(\u001b[39m\"\u001b[39;49m\u001b[39mstate_pixels\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    543\u001b[0m step_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    544\u001b[0m terminated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\envs\\box2d\\car_racing.py:603\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    600\u001b[0m trans \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mVector2((scroll_x, scroll_y))\u001b[39m.\u001b[39mrotate_rad(angle)\n\u001b[0;32m    601\u001b[0m trans \u001b[39m=\u001b[39m (WINDOW_W \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m trans[\u001b[39m0\u001b[39m], WINDOW_H \u001b[39m/\u001b[39m \u001b[39m4\u001b[39m \u001b[39m+\u001b[39m trans[\u001b[39m1\u001b[39m])\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_road(zoom, trans, angle)\n\u001b[0;32m    604\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcar\u001b[39m.\u001b[39mdraw(\n\u001b[0;32m    605\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf,\n\u001b[0;32m    606\u001b[0m     zoom,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m     mode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mstate_pixels_list\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstate_pixels\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    610\u001b[0m )\n\u001b[0;32m    612\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mflip(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf, \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\envs\\box2d\\car_racing.py:648\u001b[0m, in \u001b[0;36mCarRacing._render_road\u001b[1;34m(self, zoom, translation, angle)\u001b[0m\n\u001b[0;32m    640\u001b[0m field \u001b[39m=\u001b[39m [\n\u001b[0;32m    641\u001b[0m     (bounds, bounds),\n\u001b[0;32m    642\u001b[0m     (bounds, \u001b[39m-\u001b[39mbounds),\n\u001b[0;32m    643\u001b[0m     (\u001b[39m-\u001b[39mbounds, \u001b[39m-\u001b[39mbounds),\n\u001b[0;32m    644\u001b[0m     (\u001b[39m-\u001b[39mbounds, bounds),\n\u001b[0;32m    645\u001b[0m ]\n\u001b[0;32m    647\u001b[0m \u001b[39m# draw background\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_draw_colored_polygon(\n\u001b[0;32m    649\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msurf, field, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbg_color, zoom, translation, angle, clip\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m )\n\u001b[0;32m    652\u001b[0m \u001b[39m# draw grass patches\u001b[39;00m\n\u001b[0;32m    653\u001b[0m grass \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\envs\\box2d\\car_racing.py:762\u001b[0m, in \u001b[0;36mCarRacing._draw_colored_polygon\u001b[1;34m(self, surface, poly, color, zoom, translation, angle, clip)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m clip \u001b[39mor\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m    757\u001b[0m     (\u001b[39m-\u001b[39mMAX_SHAPE_DIM \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m coord[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m WINDOW_W \u001b[39m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[0;32m    758\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39m-\u001b[39mMAX_SHAPE_DIM \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m coord[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m WINDOW_H \u001b[39m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[0;32m    759\u001b[0m     \u001b[39mfor\u001b[39;00m coord \u001b[39min\u001b[39;00m poly\n\u001b[0;32m    760\u001b[0m ):\n\u001b[0;32m    761\u001b[0m     gfxdraw\u001b[39m.\u001b[39maapolygon(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf, poly, color)\n\u001b[1;32m--> 762\u001b[0m     gfxdraw\u001b[39m.\u001b[39;49mfilled_polygon(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msurf, poly, color)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defining the number of episodes - number of times the game will play itself either if:\n",
    "#   A. The car visits all tiles.\n",
    "#   B. Goes outside of the playfield and far from the track.\n",
    "episodes = 1\n",
    "\n",
    "# Starting a loop to play the given number of episodes.\n",
    "for episode in range(1, episodes+1):\n",
    "    \n",
    "    # Reseting the environment to get the initial state - car starts at rest in the center of the road.\n",
    "    state = env.reset()\n",
    "    \n",
    "    # Flagging to indicate whether the episode is done or not (i.e., whether the terminal state has been reached).\n",
    "    done = False\n",
    "    \n",
    "    # Initializing the score for the episode to 0.\n",
    "    score = 0 \n",
    "    \n",
    "    # Starting a loop that continues until the episode is done.\n",
    "    while not done:\n",
    "        \n",
    "        # Choosing an action randomly from the action space of the environment.\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        # Taking the chosen action in the environment, and get the next state, reward, done flag, and additional info.\n",
    "        n_state, reward, done, _, info = env.step(action)\n",
    "        \n",
    "        # Adding the reward for this step to the score.\n",
    "        score += reward\n",
    "    \n",
    "    # Printing out the score for the episode after its conclusion.\n",
    "    print(f'Episode:{episode} Score:{score}')\n",
    "\n",
    "# CLosing the environment.\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** As seen, without properly training the agent to appropriatly define the right actions to take the accumulated final scores will be very poor (negative values). \n",
    "\n",
    "In order to improve these the agent must be trained in order to:\n",
    "\n",
    "1. **Gather samples from the gameplay (i.e., running the policy);**\n",
    "2. **Fit a model that estimates the tota final return;**\n",
    "3. **Improving the policy, in order to generate at each step an action with the end goal of maximizing the final acuumulated reward.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part III: Setting up the Agent & Policy**\n",
    "\n",
    "Set up the Agent & Policy using Stable Baselines3 - a famous high-level Python library for reinforcement learning exercises."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **â€¢ Create an Environment Instance and Wrap it:**\n",
    "\n",
    "Creating a new environment instance and wrapping it with the DummyVecEnc class from Stable Baselines3. This will turn the environment into a vectorized environment that allows for multiples copies to be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the environment.\n",
    "env = gym.make(environment_name, render_mode=\"human\")\n",
    "\n",
    "# Wraping the nevironment to make it compatible with Stable Baselines3 library - which expects a vectorized environment.\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **â€¢ Setup the Agent and Policy**\n",
    "\n",
    "Creating an agent using the **Proximal Policy Optimization** algorithm.\n",
    "\n",
    "This algorithm was built in order to optimize the decisions made by an agent in a given environment in order to maximize the notion of cumulative reward. The idea behind consists of taking steps in the driection that improves the policy, but not too large ones that might harm the performance. In other words, it seeks an optimal policy that is close to the current policy. \n",
    "\n",
    "Mathematically, PPO aims to find the optimal policy Ï€(Î¸) that maximizes the objective:\n",
    "<center><img src=\"images/ppo_formula.png\"/></center>\n",
    "\n",
    "The main innovation of the this algorithm is the introduction of a \"Clipping\" mechanism that penalizes changes in the policy that deviate too much from the curren policy.\n",
    "\n",
    "In terms of the Policy, \"CNNPolicy\" - a policy architecture option that is especially good at processing grid-like data (i.e., images) was chosen. This CNN, particularly good for game environments, will take in the image-based observation from the environment, process it through its layers to detect important features, and then output an action (or a distribution over actions) that the agent should take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Agent and the Policy.\n",
    "model = PPO(\"CnnPolicy\", \n",
    "            # Defining the environment the model will use.\n",
    "            env, \n",
    "            # Defining the level of detail of training logs.\n",
    "            verbose=1,\n",
    "            # Defining the discount factor for future rewards (how much the agent cares about rewards in the distance future relative to immediate ones).\n",
    "            gamma=0.99,  \n",
    "            # Defining the trade-off between exploration (trying out new actions) and exploitation (sticking to what's known to work)\n",
    "            ent_coef=0.01, \n",
    "            # Defining the learning rate for the optimizer.\n",
    "            learning_rate=0.00025, \n",
    "            # Defining the value function coefficient - scaling factor to change the contribution of the value function loss to the total loss function.\n",
    "            vf_coef=0.5, \n",
    "            # Defining the maximum value for the gradient clipping.\n",
    "            max_grad_norm=0.5,\n",
    "            # Defining the trade-off between variance and bias - technique to reduce variance.\n",
    "            gae_lambda=0.95,\n",
    "            # Defining the clipping parameter for the policy update - how much the new policy can deviate from the old policy during each update.\n",
    "            clip_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# Defining the Agent and the Policy.\n",
    "model = PPO(\"CnnPolicy\", \n",
    "            # Defining the environment the model will use.\n",
    "            env, \n",
    "            # Defining the level of detail of training logs.\n",
    "            verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part IV: Initial Training**\n",
    "\n",
    "Initially train the model for a small number of steps to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the short model training path.\n",
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_15_Driving_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the short model timesteps - 15.\n",
    "#model.learn(total_timesteps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model.\n",
    "#model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the model.\n",
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# Loading the model to see if it was properly saved.\n",
    "model = PPO.load(PPO_path, env=env)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part V: Initial Evaluation**\n",
    "\n",
    "Evaluating the performance of the agent after being trained with the short timestepped model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-2.8309002332389355, 9.627015572041273)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the performance of the model.\n",
    "evaluate_policy(model, env, n_eval_episodes=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** Although we can see some improvements in terms of the actions that the car takes, the agent is definetly not trained as most of its time is spent on grass instead of trying to complete the track. Given such poor generated scores, the hypothesis that can be raised is that with a larger amount of training steps, the agent will be able to learn a better policy in order to take actions that will maximize the accumulated score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part VI: Training Stage**\n",
    "\n",
    "Now that the training process is understood and after confirming the poor results from only training the agent on 15 timesteps, the model will be trained for a longer period of time to improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the long model training path.\n",
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_100_Driving_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the long model on 100K timesteps.\n",
    "#model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model.\n",
    "#model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the model.\n",
    "#del model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part VII: Testing and Evaluation Stages**\n",
    "\n",
    "Evaluating the performance of the testing performed with the long timestepped model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **â€¢ Define the Environment:**\n",
    "Defining the type of environment - 'CarRacing-v2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the type of environment.\n",
    "environment_name = 'CarRacing-v2'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **â€¢ Create an Environment Instance and Wrap it:**\n",
    "\n",
    "Creating a new environment instance and wrapping it with the DummyVecEnc class from Stable Baselines3. This will turn the environment into a vectorized environment that allows for multiples copies to be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of it and setting the render mode as \"human\" so the environment can be seen on video.\n",
    "env = gym.make(environment_name, render_mode=\"human\")\n",
    "\n",
    "# Wraping the nevironment to make it compatible with Stable Baselines3 library - which expects a vectorized environment.\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **â€¢ Load the Model:**\n",
    "\n",
    "Loading the longer trained model from its orginal path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "ppo_path = os.path.join('Training', 'Saved Models', 'PPO_100_Driving_model')\n",
    "model = PPO.load(ppo_path, env=env)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **â€¢ Model Evaluation:**\n",
    "\n",
    "This step is done to measure the performance of your trained agent. Evaluation gives us an estimate of how well the agent will perform and can be used to compare different models or configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234.40571538731456, 52.17575665190816)\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance of the longer trained model.\n",
    "evalue = evaluate_policy(model, env, n_eval_episodes=2, render=True)\n",
    "print(evalue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **â€¢ Model Testing:**\n",
    "\n",
    "This step is done as a final assessment of the agent, in order to check how it would operate in the real world given the model that it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[650.002]\n",
      "Episode:2 Score:[892.3732]\n",
      "Episode:3 Score:[710.2913]\n"
     ]
    }
   ],
   "source": [
    "# Running multiple episodes and record the scores and time steps.\n",
    "episodes = 3\n",
    "scores_array = []\n",
    "timestep_arr = []\n",
    "\n",
    "# Starting a loop to play the given number of episodes.\n",
    "for episode in range(1, episodes+1):\n",
    "    # Resetting the environment to get the initial state - car starts at rest in the center of the road.\n",
    "    obs = env.reset()\n",
    "    \n",
    "    # Flagging to indicate whether the episode is done or not (i.e., whether the terminal state has been reached).\n",
    "    done = False\n",
    "\n",
    "    # Initializing the score for the episode to 0.\n",
    "    score = 0\n",
    "\n",
    "    # Initializing the timestep as 0.\n",
    "    timestep = 0\n",
    "    \n",
    "    # Starting a loop that continues until the episode is done.\n",
    "    while not done:\n",
    "\n",
    "        # Choosing an action randomly from the action space of the environment.\n",
    "        action, _ = model.predict(obs)\n",
    "\n",
    "        # Taking the chosen action in the environment, and get the next state, reward, done flag, and additional info.\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Adding the reward for this step to the score.\n",
    "        score += reward\n",
    "\n",
    "        # Incrementing the timesteps.\n",
    "        timestep += 1\n",
    "        \n",
    "        # Render the environment.\n",
    "        env.render()\n",
    "    \n",
    "    # Saving both the scores and timesteps.\n",
    "    scores_array.append(score)\n",
    "    timestep_arr.append(timestep)\n",
    "\n",
    "    # Printing out the score for the episode after its conclusion.\n",
    "    print(\"Episode:{} Score:{}\".format(episode, score))\n",
    "\n",
    "# CLosing the environment.\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Part VIII: Score Analysis**\n",
    "\n",
    "Plotting the scores and time steps for each episode to analyze the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the scores and timestep per episode.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores_array)+1), scores_array, label=\"Score\", color='red')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0,)\n",
    "plt.xticks(np.arange(1, len(scores_array)+1))\n",
    "plt.xlabel('Episodes #')\n",
    "plt.title(\"Scores over Episodes\", fontweight='bold' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** As observable, with the longer trainedstepped model the results far exceeded the ones from the first testing stages. Despite the better score values, some of irregularity on these still needs to be addressed, hence for now the challenge wasn't fully successful given that none of the runs achieved the necessary 900 points in order to pass it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
